{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datorseende - Kursprojekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import dlib\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from imutils import face_utils as fu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjects\n",
    "Predefined profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['', 'Niklas', 'Walter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### face_detector(img)\n",
    "Face detecting with haarcascades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img):\n",
    "    \n",
    "    # Image already in array-form. No need to cv.imread()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv.CascadeClassifier('C:\\\\Users\\\\Niklas\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Detecting faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # If no faces are detected, return None, None\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    # Asssigning coordinates for face\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    # Return image with only face and coordinates\n",
    "    return gray[y: y + h, x: x + w], faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare_data(data_folder_path)\n",
    "Access and prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_folder_path):\n",
    "    \n",
    "    # Accessing training data\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    faces = []\n",
    "    labels = []\n",
    "    \n",
    "    # Looping through subjects\n",
    "    for dir_name in dirs:\n",
    "        \n",
    "        if not dir_name.startswith('s'):\n",
    "            continue\n",
    "            \n",
    "        label = int(dir_name.replace('s', ''))\n",
    "        subject_dir_path = data_folder_path + '\\\\' + dir_name\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        # Looping through subject images\n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            if image_name.startswith('.'):\n",
    "                continue\n",
    "                \n",
    "            image_path = subject_dir_path + '\\\\' + image_name\n",
    "            image = cv.imread(image_path)\n",
    "            \n",
    "            # CSI ACTION\n",
    "            cv.imshow('Training data...', image)\n",
    "            cv.waitKey(50)\n",
    "            \n",
    "            #Feeding images into the face_detector function\n",
    "            face, rect = face_detector(image)\n",
    "            \n",
    "            # If face detected, add to list\n",
    "            \n",
    "            if face is None:\n",
    "                print(dir_name, ': ', image_name)\n",
    "            if face is not None:\n",
    "                faces.append(face)\n",
    "                labels.append(label)\n",
    "                \n",
    "    cv.destroyAllWindows()\n",
    "    cv.waitKey(1)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    return faces, labels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing out data\n",
    "Running training data and checking images that for some reasin did not include a face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "s1 :  30.jpg\n",
      "s2 :  22.jpg\n",
      "Data has been prepared\n",
      "Number of faces:  53\n",
      "Number of labels:  53\n"
     ]
    }
   ],
   "source": [
    "print('Preparing data...')\n",
    "faces, labels = prepare_data('training_data')\n",
    "print('Data has been prepared')\n",
    "\n",
    "print('Number of faces: ', len(faces))\n",
    "print('Number of labels: ', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our data\n",
    "Assigning our face recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw_text(img, text, x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(img, text, x, y):\n",
    "    cv.putText(img, text, (x, y), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eye_tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_tracker():\n",
    "    \n",
    "    # Assigning VideoCapture()\n",
    "    cap = cv.VideoCapture(0)\n",
    "    \n",
    "    # Importing cascade and predictor\n",
    "    face_cascade = cv.CascadeClassifier('C:\\\\Users\\\\Niklas\\\\Anaconda3\\\\Library\\\\etc\\\\lbpcascades\\\\lbpcascade_frontalface.xml')\n",
    "    p = 'shape_predictor_68_face_landmarks.dat'\n",
    "    \n",
    "    # Detector for face landmarks\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(p)\n",
    "    \n",
    "    # Global variables\n",
    "    d = {}\n",
    "    EAR = 0\n",
    "    PERCLOS = 0\n",
    "    arrClosed = []\n",
    "    arrOpen = [1]\n",
    "    \n",
    "    for i in range(250):\n",
    "        arrClosed.append(0)\n",
    "        \n",
    "    for i in range(249):\n",
    "        arrOpen.append(0)\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Getting our webcam feed, flipping it horizontally and assigning a grayscale version\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv.flip(frame, +1)\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detecting faces for facial landmarks\n",
    "        faces = detector(gray, 0)\n",
    "        \n",
    "        # Detecting coordinates around face\n",
    "        face_coords = face_cascade.detectMultiScale(gray, 1.05, 5)\n",
    "        \n",
    "        # Loop to draw rectangle around faces and recognizing the user\n",
    "        for (x, y, w, h) in face_coords:\n",
    "            \n",
    "            # Draw rectangle and assign coordinates around face\n",
    "            cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            roi_gray = gray[y: y + h, x: x + w]\n",
    "            roi_color = frame[y: y + h, x: x + w]\n",
    "            \n",
    "            # Using our face_recognizer that we trained earlier\n",
    "            label = face_recognizer.predict(roi_gray)\n",
    "            label_text = subjects[label[0]]\n",
    "            \n",
    "            # Adding name of recognized person\n",
    "            draw_text(frame, label_text, x, y - 5)\n",
    "        \n",
    "        # Loop for landmarks\n",
    "        for face in faces:\n",
    "            \n",
    "            # Shape of face\n",
    "            shape = fu.shape_to_np(predictor(gray, face))\n",
    "            \n",
    "            # Loop to draw landmarks\n",
    "            for i, (x, y) in enumerate(shape, 1):\n",
    "                \n",
    "                # Only drawing eyes\n",
    "                if i >= 37 and i <= 48:\n",
    "                    cv.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "                    \n",
    "                    # Assigning landmark coordinates in a dictionary\n",
    "                    d['coord{0}'.format(i)] = (x, y)\n",
    "\n",
    "            # Preparing coordinates for EAR calculation. earV values for vertical distances. earH for horizontal\n",
    "            earV1 = (abs(d['coord44'][0] - d['coord48'][0]), abs(d['coord44'][1] - d['coord48'][1]))\n",
    "            earV2 = (abs(d['coord45'][0] - d['coord47'][0]), abs(d['coord45'][1] - d['coord47'][1]))\n",
    "            earH = (abs(d['coord43'][0] - d['coord46'][0]), abs(d['coord43'][1] - d['coord46'][1]))\n",
    "            \n",
    "            earV = (earV1[0] + earV2[0], earV1[1] + earV2[1])\n",
    "            \n",
    "            # Final EAR-formula\n",
    "            EAR = earV[1] / (2 * earH[0])\n",
    "            \n",
    "            # Threshold for open/closed eye. If EAR < 0.21, the eye is almost closed.\n",
    "            # Appending 1 to closedFrames and removing first item in list. Timeframe of 250 frames at 10 fps\n",
    "            # Appending 0 to openFrames and removing first item in list. \n",
    "            # Couldn't get append and pop to work properly on one line\n",
    "            if EAR <= 0.21:\n",
    "                arrClosed.append(1)\n",
    "                arrClosed.pop(0)\n",
    "                arrOpen.append(0)\n",
    "                arrOpen.pop(0)\n",
    "                \n",
    "\n",
    "            # Doing the opposite\n",
    "            if EAR > 0.21:\n",
    "                arrClosed.append(0)\n",
    "                arrClosed.pop(0)\n",
    "                arrOpen.append(1)\n",
    "                arrOpen.pop(0)\n",
    "            \n",
    "            \n",
    "            # Calculating the percentage of time eyes are closed\n",
    "            PERCLOS = sum(arrClosed) / (sum(arrClosed) + sum(arrOpen))\n",
    "            \n",
    "\n",
    "        cv.putText(frame, ('EAR: ' + (str(round(EAR, 2)))), (15, 30), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2) \n",
    "        cv.putText(frame, ('PERCLOS: ' + (str(round(PERCLOS * 100, 3))) + '%'), (15, 55), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        \n",
    "        # Some PERCLOS thresholds.\n",
    "        if PERCLOS >= 0.15:\n",
    "            cv.putText(frame, ('SEVERE DROWSINESS'), (15, 80), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)    \n",
    "        if PERCLOS >= 0.07 and PERCLOS < 0.15:\n",
    "            cv.putText(frame, ('MODERATE DROWSINESS'), (15, 80), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 255), 2)\n",
    "        if PERCLOS < 0.07:\n",
    "            cv.putText(frame, ('LOW DROWSINESS'), (15, 80), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "            \n",
    "        \n",
    "        cv.imshow('Frame', frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break   \n",
    "            \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "#     print(closedFrames + openFrames)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eye_tracker()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
