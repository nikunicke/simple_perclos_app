{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reqiuired libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils as fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_landmarks():\n",
    "    \n",
    "    # Assign trained data\n",
    "    p = 'shape_predictor_68_face_landmarks.dat'\n",
    "    \n",
    "    # Assign dlib fuctions for face detection\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(p)\n",
    "    \n",
    "    # Assign webcam\n",
    "    cap = cv.VideoCapture(0)\n",
    "    \n",
    "    # Global variables\n",
    "    d = {}\n",
    "    EAR = 0\n",
    "    openFrames = 0\n",
    "    closedFrames = 0\n",
    "    PERCLOS = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Get webcam frame and convert to grayscale\n",
    "        _, frame = cap.read()\n",
    "        \n",
    "        frame = cv.flip(frame, + 1)\n",
    "        \n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detector(gray, 0)\n",
    "        \n",
    "        \n",
    "        # Detecting shape for every face in frame\n",
    "        for face in faces:\n",
    "            \n",
    "            # Get coordinates of shape for every frame\n",
    "            shape = fu.shape_to_np(predictor(gray, face))\n",
    "            \n",
    "            # Drawning points along the shape. Enumerating loop to differentiate between points along the shape\n",
    "            for i, (x, y) in enumerate(shape, 1):\n",
    "                \n",
    "                # Restricting to only eyes\n",
    "                if i >= 37 and i <= 48:\n",
    "                    cv.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "                    \n",
    "                    # Assign coordinates to variables inside a dictionary\n",
    "                    d['coord{0}'.format(i)] = (x, y)\n",
    "            # Assign values for EAR calculation. First all the vertical points(1, 2) and then the horizontal points(3)        \n",
    "            earV1 = (abs(d['coord44'][0] - d['coord48'][0]), abs(d['coord44'][1] - d['coord48'][1])) # 1\n",
    "            earV2 = (abs(d['coord45'][0] - d['coord47'][0]), abs(d['coord45'][1] - d['coord47'][1])) # 2\n",
    "            earH = (abs(d['coord43'][0] - d['coord46'][0]), abs(d['coord43'][1] - d['coord46'][1]))  # 3\n",
    "            \n",
    "            # Adding y-difference of vertical points\n",
    "            earV = (earV1[0] + earV2[0], earV1[1] + earV2[1])\n",
    "\n",
    "            # EAR calculation\n",
    "            EAR = earV[1] / (2 * earH[0])\n",
    "            \n",
    "            # Determining threshold for when eye is closed and counting amount of frames eyes remain closed\n",
    "            if EAR <= 0.19:\n",
    "                closedFrames += 1\n",
    "            # Counting amount of frames eyes remain open\n",
    "            if EAR > 0.19:\n",
    "                openFrames += 1\n",
    "            \n",
    "            # Calculating PERCLOS without converting to percentage. Done later.\n",
    "            PERCLOS = (closedFrames / (closedFrames + openFrames))\n",
    "            \n",
    "        \n",
    "        # Writing real-time values on frame        \n",
    "        cv.putText(frame, ('EAR: ' + (str(round(EAR, 2)))), (15, 30), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)            \n",
    "        cv.putText(frame, ('PERCLOS: ' + (str(round(PERCLOS * 100, 3))) + '%'), (15, 55), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        \n",
    "        # Determining PERCLOS thresholds\n",
    "        if PERCLOS >= 0.15:\n",
    "            cv.putText(frame, ('SEVERE DROWSINESS'), (15, 80), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)    \n",
    "        if PERCLOS >= 0.07 and PERCLOS < 0.15:\n",
    "            cv.putText(frame, ('MODERATE DROWSINESS'), (15, 80), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 255), 2)\n",
    "        if PERCLOS < 0.07:\n",
    "            cv.putText(frame, ('LOW DROWSINESS'), (15, 80), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display frame\n",
    "        cv.imshow('Feed', frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "\n",
    "            \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    PERCLOS = (closedFrames / (closedFrames + openFrames))\n",
    "    \n",
    "    # Output final PERCLOS result\n",
    "    print('PERCLOS: ', round(PERCLOS, 2) * 100, '%')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCLOS:  12.0 %\n"
     ]
    }
   ],
   "source": [
    "eye_landmarks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
